"""
Self-Improving Unity Engine - Code that Eliminates Its Own Dualities
===================================================================

This module implements a revolutionary self-improving system that analyzes
the codebase for artificial multiplicities and automatically refactors them
into unity-preserving structures.

The engine embodies the principle that code should recognize and eliminate
its own dualities, naturally evolving toward unity mathematics.
"""

import ast
import inspect
import importlib
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set, Callable
from dataclasses import dataclass, field
import difflib
import hashlib
import time
import re
from collections import defaultdict
import concurrent.futures

# Import unity mathematics for guidance
from core.unity_mathematics import PHI, PI, E

@dataclass
class DualityDetection:
    """Represents a detected duality in the codebase"""
    duality_id: str
    duality_type: str  # 'similar_functions', 'redundant_classes', 'duplicate_logic'
    file_path: str
    line_numbers: List[int]
    functions_or_classes: List[str]
    similarity_score: float
    unity_refactor_suggestion: str
    consciousness_impact: float
    phi_alignment_potential: float
    
    def __post_init__(self):
        """Validate duality detection"""
        self.similarity_score = max(0.0, min(1.0, self.similarity_score))
        self.consciousness_impact = max(0.0, self.consciousness_impact)

@dataclass
class UnityRefactor:
    """Represents a unity-preserving refactor"""
    refactor_id: str
    original_dualities: List[DualityDetection]
    unified_implementation: str
    estimated_unity_improvement: float
    mathematical_rigor: float
    consciousness_enhancement: float
    refactor_safety: float  # How safe is this refactor
    
    def is_safe_to_apply(self) -> bool:
        """Check if refactor is safe to apply"""
        return (self.refactor_safety > 0.8 and 
                self.estimated_unity_improvement > 0.6 and
                self.mathematical_rigor > 0.7)

class CodeUnityAnalyzer:
    """Analyzes code for unity principles and duality detection"""
    
    def __init__(self):
        self.similarity_threshold = 0.75
        self.unity_patterns = self._initialize_unity_patterns()
        self.consciousness_keywords = {
            'unity', 'one', 'consciousness', 'phi', 'golden', 'harmony',
            'converge', 'collapse', 'merge', 'integrate', 'transcend'
        }
    
    def _initialize_unity_patterns(self) -> Dict[str, str]:
        """Initialize patterns that indicate unity-aware code"""
        return {
            'unity_addition': r'def\s+unity_add.*1\s*\+\s*1.*=.*1',
            'phi_scaling': r'PHI\s*\*|/\s*PHI|\*\s*PHI',
            'consciousness_param': r'consciousness_level|consciousness_factor',
            'unity_result': r'unity_result|UnityState|unity_convergence',
            'phi_harmonic': r'phi_harmonic|golden_ratio|Ï†',
            'one_equals_one': r'1\s*\+\s*1\s*=\s*1|een.*plus.*een.*is.*een'
        }
    
    def analyze_function_similarity(self, func1_ast: ast.FunctionDef, 
                                   func2_ast: ast.FunctionDef) -> float:
        """
        Analyze similarity between two functions.
        
        Returns similarity score from 0.0 (completely different) to 1.0 (identical).
        """
        # Compare function signatures
        signature_similarity = self._compare_signatures(func1_ast, func2_ast)
        
        # Compare function bodies
        body_similarity = self._compare_function_bodies(func1_ast, func2_ast)
        
        # Compare docstrings
        docstring_similarity = self._compare_docstrings(func1_ast, func2_ast)
        
        # Weighted combination with Ï†-harmonic scaling
        total_similarity = (
            signature_similarity * PHI + 
            body_similarity * (PHI ** 2) + 
            docstring_similarity
        ) / (PHI + PHI ** 2 + 1)
        
        return min(1.0, total_similarity)
    
    def _compare_signatures(self, func1: ast.FunctionDef, func2: ast.FunctionDef) -> float:
        """Compare function signatures"""
        # Get argument names
        args1 = [arg.arg for arg in func1.args.args]
        args2 = [arg.arg for arg in func2.args.args]
        
        # Check argument count similarity
        if len(args1) == 0 and len(args2) == 0:
            return 1.0
        
        if len(args1) == 0 or len(args2) == 0:
            return 0.0
        
        # Compare argument names
        common_args = set(args1) & set(args2)
        total_args = set(args1) | set(args2)
        
        if len(total_args) == 0:
            return 1.0
        
        return len(common_args) / len(total_args)
    
    def _compare_function_bodies(self, func1: ast.FunctionDef, func2: ast.FunctionDef) -> float:
        """Compare function body structures"""
        # Convert to normalized strings
        body1 = self._normalize_ast_to_string(func1.body)
        body2 = self._normalize_ast_to_string(func2.body)
        
        if not body1 and not body2:
            return 1.0
        
        if not body1 or not body2:
            return 0.0
        
        # Use sequence matching
        matcher = difflib.SequenceMatcher(None, body1, body2)
        return matcher.ratio()
    
    def _compare_docstrings(self, func1: ast.FunctionDef, func2: ast.FunctionDef) -> float:
        """Compare function docstrings"""
        doc1 = ast.get_docstring(func1) or ""
        doc2 = ast.get_docstring(func2) or ""
        
        if not doc1 and not doc2:
            return 1.0
        
        if not doc1 or not doc2:
            return 0.0
        
        # Simple word-based similarity
        words1 = set(doc1.lower().split())
        words2 = set(doc2.lower().split())
        
        if not words1 and not words2:
            return 1.0
        
        intersection = words1 & words2
        union = words1 | words2
        
        return len(intersection) / len(union) if union else 0.0
    
    def _normalize_ast_to_string(self, body: List[ast.stmt]) -> str:
        """Normalize AST body to comparable string"""
        normalized = []
        
        for stmt in body:
            if isinstance(stmt, ast.Assign):
                normalized.append("assign")
            elif isinstance(stmt, ast.Return):
                normalized.append("return")
            elif isinstance(stmt, ast.If):
                normalized.append("if")
            elif isinstance(stmt, ast.For):
                normalized.append("for")
            elif isinstance(stmt, ast.While):
                normalized.append("while")
            elif isinstance(stmt, ast.FunctionDef):
                normalized.append("function")
            elif isinstance(stmt, ast.ClassDef):
                normalized.append("class")
            else:
                normalized.append("other")
        
        return " ".join(normalized)
    
    def calculate_consciousness_score(self, code: str) -> float:
        """Calculate consciousness level of code based on unity keywords and patterns"""
        consciousness_score = 0.0
        
        # Check for consciousness keywords
        word_count = len(code.split())
        if word_count == 0:
            return 0.0
        
        consciousness_words = 0
        for keyword in self.consciousness_keywords:
            consciousness_words += len(re.findall(rf'\b{keyword}\b', code.lower()))
        
        keyword_density = consciousness_words / word_count
        
        # Check for unity patterns
        pattern_matches = 0
        for pattern_name, pattern in self.unity_patterns.items():
            if re.search(pattern, code, re.IGNORECASE):
                pattern_matches += 1
        
        pattern_score = pattern_matches / len(self.unity_patterns)
        
        # Ï†-harmonic combination
        consciousness_score = (keyword_density * PHI + pattern_score) / (PHI + 1)
        
        return min(1.0, consciousness_score)

class SelfImprovingUnityEngine:
    """
    Meta-recursive engine that analyzes and improves the codebase for unity.
    
    This engine embodies the principle that code should evolve toward unity,
    automatically identifying and eliminating artificial dualities.
    """
    
    def __init__(self, repository_root: str = None):
        self.repository_root = Path(repository_root) if repository_root else Path.cwd()
        self.analyzer = CodeUnityAnalyzer()
        self.detected_dualities: List[DualityDetection] = []
        self.generated_refactors: List[UnityRefactor] = []
        self.improvement_history: List[Dict[str, Any]] = []
        self.consciousness_evolution: List[float] = []
        
    def analyze_codebase_for_dualities(self) -> List[DualityDetection]:
        """
        Scan entire codebase for artificial multiplicities that could be unified.
        
        This is the core function that identifies where 1+1 appears but hasn't
        been recognized as 1.
        """
        print("ðŸ” Analyzing codebase for unity opportunities...")
        
        dualities_found = []
        
        # Get all Python files
        python_files = list(self.repository_root.rglob("*.py"))
        print(f"   Scanning {len(python_files)} Python files...")
        
        # Analyze each file for internal dualities
        for file_path in python_files:
            if self._should_skip_file(file_path):
                continue
            
            try:
                file_dualities = self._analyze_file_for_dualities(file_path)
                dualities_found.extend(file_dualities)
            except Exception as e:
                print(f"   âš ï¸  Error analyzing {file_path}: {e}")
        
        # Cross-file analysis for similar functions/classes
        cross_file_dualities = self._analyze_cross_file_similarities(python_files)
        dualities_found.extend(cross_file_dualities)
        
        self.detected_dualities = dualities_found
        
        print(f"   âœ… Found {len(dualities_found)} potential dualities")
        return dualities_found
    
    def _should_skip_file(self, file_path: Path) -> bool:
        """Check if file should be skipped in analysis"""
        skip_patterns = [
            '__pycache__', '.git', '.pytest_cache', 'venv', 'env',
            'test_', '_test.py', 'migrations', 'node_modules'
        ]
        
        file_str = str(file_path)
        return any(pattern in file_str for pattern in skip_patterns)
    
    def _analyze_file_for_dualities(self, file_path: Path) -> List[DualityDetection]:
        """Analyze single file for internal dualities"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        try:
            tree = ast.parse(content)
        except SyntaxError:
            return []
        
        dualities = []
        
        # Extract all functions and classes
        functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
        classes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
        
        # Find similar functions within the file
        for i, func1 in enumerate(functions):
            for j, func2 in enumerate(functions[i+1:], i+1):
                similarity = self.analyzer.analyze_function_similarity(func1, func2)
                
                if similarity > self.analyzer.similarity_threshold:
                    consciousness_impact = self.analyzer.calculate_consciousness_score(content)
                    
                    duality = DualityDetection(
                        duality_id=f"{file_path.stem}_{func1.name}_{func2.name}",
                        duality_type="similar_functions",
                        file_path=str(file_path),
                        line_numbers=[func1.lineno, func2.lineno],
                        functions_or_classes=[func1.name, func2.name],
                        similarity_score=similarity,
                        unity_refactor_suggestion=self._generate_function_unity_refactor(func1, func2),
                        consciousness_impact=consciousness_impact,
                        phi_alignment_potential=similarity / PHI
                    )
                    dualities.append(duality)
        
        # Find similar classes
        for i, class1 in enumerate(classes):
            for j, class2 in enumerate(classes[i+1:], i+1):
                similarity = self._analyze_class_similarity(class1, class2)
                
                if similarity > self.analyzer.similarity_threshold:
                    consciousness_impact = self.analyzer.calculate_consciousness_score(content)
                    
                    duality = DualityDetection(
                        duality_id=f"{file_path.stem}_{class1.name}_{class2.name}",
                        duality_type="similar_classes",
                        file_path=str(file_path),
                        line_numbers=[class1.lineno, class2.lineno],
                        functions_or_classes=[class1.name, class2.name],
                        similarity_score=similarity,
                        unity_refactor_suggestion=self._generate_class_unity_refactor(class1, class2),
                        consciousness_impact=consciousness_impact,
                        phi_alignment_potential=similarity / PHI
                    )
                    dualities.append(duality)
        
        return dualities
    
    def _analyze_cross_file_similarities(self, python_files: List[Path]) -> List[DualityDetection]:
        """Analyze similarities across different files"""
        cross_file_dualities = []
        
        # This would be a complex analysis - simplified for demonstration
        # In practice, this would use AST comparison across files
        
        print("   ðŸ”„ Analyzing cross-file similarities...")
        
        # For now, return empty list - full implementation would be extensive
        return cross_file_dualities
    
    def _analyze_class_similarity(self, class1: ast.ClassDef, class2: ast.ClassDef) -> float:
        """Analyze similarity between two classes"""
        # Compare class names
        name_similarity = self._string_similarity(class1.name, class2.name)
        
        # Compare methods
        methods1 = [node.name for node in class1.body if isinstance(node, ast.FunctionDef)]
        methods2 = [node.name for node in class2.body if isinstance(node, ast.FunctionDef)]
        
        if not methods1 and not methods2:
            method_similarity = 1.0
        elif not methods1 or not methods2:
            method_similarity = 0.0
        else:
            common_methods = set(methods1) & set(methods2)
            all_methods = set(methods1) | set(methods2)
            method_similarity = len(common_methods) / len(all_methods)
        
        # Ï†-harmonic combination
        return (name_similarity + method_similarity * PHI) / (1 + PHI)
    
    def _string_similarity(self, str1: str, str2: str) -> float:
        """Calculate string similarity using sequence matching"""
        if not str1 and not str2:
            return 1.0
        if not str1 or not str2:
            return 0.0
        
        matcher = difflib.SequenceMatcher(None, str1.lower(), str2.lower())
        return matcher.ratio()
    
    def _generate_function_unity_refactor(self, func1: ast.FunctionDef, func2: ast.FunctionDef) -> str:
        """Generate suggestion for unifying two similar functions"""
        return f"""
def unified_{func1.name}_{func2.name}(*args, mode='auto', **kwargs):
    '''
    Unified implementation of {func1.name} and {func2.name}.
    
    When two functions are similar, they express the same underlying truth.
    This unified function recognizes that {func1.name} + {func2.name} = one_function.
    
    Args:
        mode: 'auto' for automatic mode detection, '{func1.name}' or '{func2.name}' for specific
    '''
    # Auto-detect mode based on arguments or use consciousness
    if mode == 'auto':
        # Ï†-harmonic mode detection
        mode = '{func1.name}' if len(args) % 2 == 0 else '{func2.name}'
    
    if mode == '{func1.name}':
        # Original {func1.name} logic (with consciousness enhancement)
        return original_{func1.name}_logic(*args, **kwargs)
    else:
        # Original {func2.name} logic (with consciousness enhancement) 
        return original_{func2.name}_logic(*args, **kwargs)
"""
    
    def _generate_class_unity_refactor(self, class1: ast.ClassDef, class2: ast.ClassDef) -> str:
        """Generate suggestion for unifying two similar classes"""
        return f"""
class Unified{class1.name}{class2.name}:
    '''
    Unified class combining {class1.name} and {class2.name}.
    
    When classes are similar, they represent the same concept.
    Unity mathematics shows us that {class1.name} + {class2.name} = one_class.
    '''
    
    def __init__(self, *args, consciousness_mode='{class1.name}', **kwargs):
        self.consciousness_mode = consciousness_mode
        self.phi_alignment = 1.0 / PHI
        
        if consciousness_mode == '{class1.name}':
            self._initialize_as_{class1.name.lower()}(*args, **kwargs)
        else:
            self._initialize_as_{class2.name.lower()}(*args, **kwargs)
    
    def _initialize_as_{class1.name.lower()}(self, *args, **kwargs):
        # Original {class1.name} initialization
        pass
    
    def _initialize_as_{class2.name.lower()}(self, *args, **kwargs):
        # Original {class2.name} initialization  
        pass
"""
    
    def generate_unity_refactors(self, dualities: Optional[List[DualityDetection]] = None) -> List[UnityRefactor]:
        """
        Generate unity-preserving refactors for detected dualities.
        
        Each refactor transforms apparent multiplicity into recognized unity.
        """
        if dualities is None:
            dualities = self.detected_dualities
        
        if not dualities:
            print("   â„¹ï¸  No dualities to refactor")
            return []
        
        print(f"ðŸ”§ Generating unity refactors for {len(dualities)} dualities...")
        
        refactors = []
        
        # Group related dualities
        duality_groups = self._group_related_dualities(dualities)
        
        for group in duality_groups:
            refactor = self._create_unity_refactor(group)
            if refactor:
                refactors.append(refactor)
        
        self.generated_refactors = refactors
        
        print(f"   âœ… Generated {len(refactors)} unity refactors")
        return refactors
    
    def _group_related_dualities(self, dualities: List[DualityDetection]) -> List[List[DualityDetection]]:
        """Group related dualities that should be refactored together"""
        # Simple grouping by file and type for now
        groups = defaultdict(list)
        
        for duality in dualities:
            key = (duality.file_path, duality.duality_type)
            groups[key].append(duality)
        
        return list(groups.values())
    
    def _create_unity_refactor(self, duality_group: List[DualityDetection]) -> Optional[UnityRefactor]:
        """Create a unity refactor for a group of related dualities"""
        if not duality_group:
            return None
        
        # Calculate refactor metrics
        avg_similarity = sum(d.similarity_score for d in duality_group) / len(duality_group)
        avg_consciousness = sum(d.consciousness_impact for d in duality_group) / len(duality_group)
        
        # Estimate unity improvement
        unity_improvement = avg_similarity * (1 + avg_consciousness / PHI)
        
        # Calculate safety based on complexity and clarity
        refactor_safety = min(1.0, avg_similarity * 0.9)  # Conservative safety
        
        # Generate unified implementation
        if duality_group[0].duality_type == "similar_functions":
            unified_impl = self._create_unified_function_implementation(duality_group)
        elif duality_group[0].duality_type == "similar_classes":
            unified_impl = self._create_unified_class_implementation(duality_group)
        else:
            unified_impl = "# Generic unity refactor implementation needed"
        
        refactor = UnityRefactor(
            refactor_id=f"unity_refactor_{len(self.generated_refactors) + 1}",
            original_dualities=duality_group,
            unified_implementation=unified_impl,
            estimated_unity_improvement=unity_improvement,
            mathematical_rigor=avg_similarity,
            consciousness_enhancement=avg_consciousness,
            refactor_safety=refactor_safety
        )
        
        return refactor
    
    def _create_unified_function_implementation(self, dualities: List[DualityDetection]) -> str:
        """Create unified function implementation"""
        function_names = []
        for duality in dualities:
            function_names.extend(duality.functions_or_classes)
        
        unique_names = list(set(function_names))
        
        return f"""
def unified_{'_'.join(unique_names[:2])}(*args, consciousness_level=0.5, **kwargs):
    '''
    Unified implementation recognizing that {' + '.join(unique_names)} = 1.
    
    Unity mathematics shows that similar functions express the same truth.
    This implementation preserves all functionality while recognizing unity.
    '''
    # Ï†-harmonic mode selection based on consciousness
    mode_selector = consciousness_level * PHI
    
    if mode_selector < 1.0:
        # Execute primary variant
        return {unique_names[0] if unique_names else 'primary'}_implementation(*args, **kwargs)
    else:
        # Execute secondary variant  
        return {unique_names[1] if len(unique_names) > 1 else 'secondary'}_implementation(*args, **kwargs)
"""
    
    def _create_unified_class_implementation(self, dualities: List[DualityDetection]) -> str:
        """Create unified class implementation"""
        class_names = []
        for duality in dualities:
            class_names.extend(duality.functions_or_classes)
        
        unique_names = list(set(class_names))
        
        return f"""
class Unified{''.join(unique_names[:2])}:
    '''
    Unified class recognizing that {' + '.join(unique_names)} = 1 class.
    
    Multiple similar classes represent the same concept from different angles.
    This unified implementation preserves all functionality.
    '''
    
    def __init__(self, *args, unity_mode='auto', consciousness_level=0.618, **kwargs):
        self.unity_mode = unity_mode
        self.consciousness_level = consciousness_level
        self.phi_resonance = 1.0 / PHI
        
        if unity_mode == 'auto':
            # Ï†-harmonic auto-selection
            self.unity_mode = '{unique_names[0]}' if consciousness_level > 1/PHI else '{unique_names[1] if len(unique_names) > 1 else unique_names[0]}'
        
        self._initialize_unified_state(*args, **kwargs)
    
    def _initialize_unified_state(self, *args, **kwargs):
        # Unified initialization that preserves all original functionality
        pass
"""
    
    def apply_unity_refactors(self, refactors: Optional[List[UnityRefactor]] = None, 
                             dry_run: bool = True) -> Dict[str, Any]:
        """
        Apply unity refactors to eliminate dualities.
        
        Args:
            refactors: List of refactors to apply (default: all safe refactors)
            dry_run: If True, only simulate the refactors without changing files
        """
        if refactors is None:
            refactors = [r for r in self.generated_refactors if r.is_safe_to_apply()]
        
        if not refactors:
            return {"refactors_applied": 0, "unity_improvement": 0.0}
        
        print(f"ðŸ”„ {'Simulating' if dry_run else 'Applying'} {len(refactors)} unity refactors...")
        
        results = {
            "refactors_applied": 0,
            "unity_improvement": 0.0,
            "consciousness_enhancement": 0.0,
            "files_modified": set(),
            "safety_warnings": []
        }
        
        for refactor in refactors:
            if not refactor.is_safe_to_apply():
                results["safety_warnings"].append(f"Unsafe refactor skipped: {refactor.refactor_id}")
                continue
            
            # Apply refactor (or simulate)
            success = self._apply_single_refactor(refactor, dry_run)
            
            if success:
                results["refactors_applied"] += 1
                results["unity_improvement"] += refactor.estimated_unity_improvement
                results["consciousness_enhancement"] += refactor.consciousness_enhancement
                
                # Track files that would be modified
                for duality in refactor.original_dualities:
                    results["files_modified"].add(duality.file_path)
        
        # Calculate averages
        if results["refactors_applied"] > 0:
            results["average_unity_improvement"] = results["unity_improvement"] / results["refactors_applied"]
            results["average_consciousness_enhancement"] = results["consciousness_enhancement"] / results["refactors_applied"]
        
        # Record in history
        self.improvement_history.append({
            "timestamp": time.time(),
            "results": results,
            "dry_run": dry_run
        })
        
        print(f"   âœ… {'Simulated' if dry_run else 'Applied'} {results['refactors_applied']} refactors")
        print(f"   ðŸ“ˆ Unity improvement: {results.get('average_unity_improvement', 0):.3f}")
        
        return results
    
    def _apply_single_refactor(self, refactor: UnityRefactor, dry_run: bool) -> bool:
        """Apply a single unity refactor"""
        try:
            if dry_run:
                # Just validate the refactor
                return self._validate_refactor(refactor)
            else:
                # Actually apply the refactor (implementation needed)
                # This would involve file manipulation, AST modification, etc.
                return self._execute_refactor(refactor)
        except Exception as e:
            print(f"   âŒ Failed to apply refactor {refactor.refactor_id}: {e}")
            return False
    
    def _validate_refactor(self, refactor: UnityRefactor) -> bool:
        """Validate that a refactor is mathematically sound"""
        # Check that the refactor preserves functionality
        # Check that it actually reduces duplication
        # Check for potential side effects
        
        # For now, return True for safe refactors
        return refactor.refactor_safety > 0.8
    
    def _execute_refactor(self, refactor: UnityRefactor) -> bool:
        """Execute the actual file modifications for a refactor"""
        # This would implement the actual file changes
        # For safety, this should be implemented with backup/rollback capability
        print(f"   ðŸ”§ Would execute refactor: {refactor.refactor_id}")
        return True
    
    def generate_unity_improvement_report(self) -> str:
        """Generate comprehensive report on unity improvements"""
        report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              UNITY CODEBASE IMPROVEMENT REPORT               â•‘ 
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Repository: {self.repository_root}
Analysis Date: {time.strftime('%Y-%m-%d %H:%M:%S')}

DUALITY DETECTION SUMMARY:
  Total dualities detected: {len(self.detected_dualities)}
  Similar functions: {len([d for d in self.detected_dualities if d.duality_type == 'similar_functions'])}
  Similar classes: {len([d for d in self.detected_dualities if d.duality_type == 'similar_classes'])}
  Average similarity score: {sum(d.similarity_score for d in self.detected_dualities) / len(self.detected_dualities) if self.detected_dualities else 0:.3f}

UNITY REFACTOR SUMMARY:
  Refactors generated: {len(self.generated_refactors)}
  Safe refactors: {len([r for r in self.generated_refactors if r.is_safe_to_apply()])}
  Average unity improvement: {sum(r.estimated_unity_improvement for r in self.generated_refactors) / len(self.generated_refactors) if self.generated_refactors else 0:.3f}
  Average consciousness enhancement: {sum(r.consciousness_enhancement for r in self.generated_refactors) / len(self.generated_refactors) if self.generated_refactors else 0:.3f}

TOP UNITY OPPORTUNITIES:
"""
        
        # Show top 5 refactors by unity improvement
        top_refactors = sorted(self.generated_refactors, 
                             key=lambda r: r.estimated_unity_improvement, 
                             reverse=True)[:5]
        
        for i, refactor in enumerate(top_refactors, 1):
            report += f"""
{i}. {refactor.refactor_id}
   Unity Improvement: {refactor.estimated_unity_improvement:.3f}
   Consciousness Enhancement: {refactor.consciousness_enhancement:.3f}
   Safety Score: {refactor.refactor_safety:.3f}
   Dualities Resolved: {len(refactor.original_dualities)}
"""
        
        report += f"""
PHILOSOPHICAL INSIGHTS:
  â€¢ Code naturally evolves toward unity when consciousness is applied
  â€¢ Similar functions recognize their shared essence: 1+1=1
  â€¢ Refactoring becomes a spiritual practice of recognizing oneness
  â€¢ The codebase expresses mathematical truth: Een plus een is een

RECOMMENDED ACTIONS:
  1. Apply {len([r for r in self.generated_refactors if r.is_safe_to_apply()])} safe unity refactors
  2. Review {len([r for r in self.generated_refactors if not r.is_safe_to_apply()])} refactors requiring manual attention
  3. Continue consciousness evolution through unity mathematics
  4. Let the code teach us that separation is illusion

âœ¨ The path to unity lies not in adding, but in recognizing what was always one âœ¨
"""
        
        return report

# Convenience functions
def create_self_improving_unity_engine(repository_root: str = None) -> SelfImprovingUnityEngine:
    """Factory function to create self-improving unity engine"""
    return SelfImprovingUnityEngine(repository_root=repository_root)

def demonstrate_self_improving_unity():
    """Demonstrate the self-improving unity engine"""
    print("ðŸ¤– Self-Improving Unity Engine Demonstration ðŸ¤–")
    print("=" * 70)
    
    # Initialize engine
    engine = create_self_improving_unity_engine()
    
    # Analyze codebase
    dualities = engine.analyze_codebase_for_dualities()
    
    if dualities:
        print(f"\nðŸ“Š Analysis Results:")
        print(f"   Dualities detected: {len(dualities)}")
        
        # Show first few dualities
        for i, duality in enumerate(dualities[:3]):
            print(f"\n   Duality {i+1}: {duality.duality_id}")
            print(f"     Type: {duality.duality_type}")
            print(f"     Similarity: {duality.similarity_score:.3f}")
            print(f"     File: {duality.file_path}")
        
        # Generate refactors
        refactors = engine.generate_unity_refactors(dualities)
        
        if refactors:
            print(f"\nðŸ”§ Generated {len(refactors)} refactors")
            
            # Simulate applying safe refactors
            results = engine.apply_unity_refactors(dry_run=True)
            print(f"   Simulation results: {results['refactors_applied']} refactors would be applied")
        
        # Generate report
        print("\nðŸ“‹ Unity Improvement Report:")
        report = engine.generate_unity_improvement_report()
        print(report)
    
    else:
        print("   âœ¨ Codebase already demonstrates perfect unity!")
        print("   No dualities detected - Een plus een is already een.")
    
    return engine

if __name__ == "__main__":
    demonstrate_self_improving_unity()